{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2\n",
    "from generator import Generator\n",
    "from models import *\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Tensorflow backend to avoid full GPU pre-loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config = config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data generator\n",
    "\n",
    "This is required to set some variables during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Loading Generator\"\n",
    "# Hardcoding because codes will mostly run from my account.\n",
    "# Also adding sys.argv stuff with defaults is a pain.\n",
    "gen = Generator(dataset_directory = '../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models requred for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "base_model = InceptionV3(weights = 'imagenet', include_top = True, input_shape = (299, 299, 3))\n",
    "img_model =  Model(\n",
    "        input = base_model.input,\n",
    "        outputs = [base_model.get_layer('mixed10').output])\n",
    "target_size = (299, 299)\n",
    "print img_model.output_shape\n",
    "output_shape = img_model.output_shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('../data/models/attention_flickr_epoch_120.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model summary (text based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model summary (flow chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Someone fill this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing images individually\n",
    "The following code randomly selects an image from validation dataset which is not used for training and displays the caption for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = ['3071676551_a65741e372.jpg']\n",
    "dataset_directory = '../data/flicker8k'\n",
    "\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "\n",
    "preprocessed_images = []\n",
    "number_of_images = len(image_filenames)\n",
    "img_input = []\n",
    "\n",
    "# Iterate over all images and preprocess them\n",
    "for img_id, img_name in enumerate(image_filenames): # For coco make 3D array , do batch\n",
    "    img_filepath = dataset_directory + '/Flickr8k_Dataset/' + img_name\n",
    "    # Image preprocessing\n",
    "    img = image.load_img(img_filepath, target_size = target_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    preprocessed_images.append(np.squeeze(img))\n",
    "\n",
    "preprocessed_images = np.asarray(preprocessed_images)\n",
    "img_features = img_model.predict(preprocessed_images)\n",
    "\n",
    "text_in = np.zeros((1,gen.max_token_len))\n",
    "text_in[0][0] = gen.token_to_id['<start>']\n",
    "\n",
    "predictions = []\n",
    "activations = []\n",
    "for arg in range(gen.max_token_len-1):\n",
    "    pred = model.predict([img_features, text_in])\n",
    "    tok = np.argmax(pred[0][arg])\n",
    "    word = gen.id_to_token[tok]\n",
    "    text_in[0][arg+1] = tok\n",
    "    if word == '<end>':\n",
    "        break\n",
    "    predictions.append(word)\n",
    "predictions.append('.')\n",
    "print ' '.join(predictions)\n",
    "Image(filename= dataset_directory + '/Flickr8k_Dataset/' + image_filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the attention map for the above test\n",
    "\n",
    "Run this only after running the above block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "for i in range(1, len(predictions) - 1):\n",
    "    text_in[0][i] = gen.token_to_id[predictions[i]]\n",
    "\n",
    "layer_name = 'time_distributed_6'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "pred = intermediate_layer_model.predict([img_features, text_in])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "I = plt.imread(dataset_directory + '/Flickr8k_Dataset/' + image_filenames[0])\n",
    "print predictions[0]\n",
    "for i in range(len(predictions) - 2):\n",
    "    plt.subplot(len(predictions) / columns + 1, columns, i + 1)\n",
    "    plt.imshow(I)\n",
    "    att = pred[0,i,:].reshape((8,8), order = 'A')\n",
    "    plt.imshow(att, alpha = 0.7, interpolation='bilinear', \n",
    "               cmap='gray', extent=[0, I.shape[1], I.shape[0], 0])\n",
    "    plt.title(predictions[i+1])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## For generating test results in bulk\n",
    "### Preprocessing\n",
    "In process_images.py change the following as per requirements:\n",
    "- dataset_directory --> Should be path to extracted dataset dreictory (like ~repo/data/COCO/extracted).\n",
    "- img_list_file = 'val2014'--> Make sure to use val2014. Captions are not available for the test files in the dataset we have.\n",
    "- save_name --> Name of the image features file to save (like test_features.h5).\n",
    "- images_per_step --> Lower number for systems with lower RAM (this is your physical RAM not your GPU memory.\n",
    "- batch_size --> Lower number for systems with lower GPU memory (VRAM if running on CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import time\n",
    "import progressbar\n",
    "\n",
    "with open('../data/flicker8k/preprocessed/test_captions.txt') as captions_file:\n",
    "    captions = captions_file.read().split('\\n')\n",
    "    \n",
    "class Caption:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.captions = ['','','','','']\n",
    "        self.result = ''\n",
    "        \n",
    "    def add(self, caption_number, caption):\n",
    "        self.captions[caption_number] = caption\n",
    "        \n",
    "test_results = {}\n",
    "\n",
    "print('Preprocessing results:')\n",
    "bar = progressbar.ProgressBar(\n",
    "        term_width = 56,\n",
    "        max_value = len(captions),\n",
    "        widgets = [\n",
    "            progressbar.Counter(format='%(value)04d/%(max_value)d'),\n",
    "            progressbar.Bar('=', '[', ']', '.'),\n",
    "            ' ',\n",
    "            progressbar.ETA()\n",
    "            ])\n",
    "\n",
    "for pos, caption in enumerate(captions):\n",
    "    if len(caption) < 5:\n",
    "        continue\n",
    "    caption = caption.split('\\t')\n",
    "    img_name = caption[0].split('#')\n",
    "    caption_number = int(img_name[1])\n",
    "    img_name = img_name[0]\n",
    "    caption = caption[1].lower()\n",
    "    \n",
    "    if pos % 25 == 0:\n",
    "        bar.update(pos)\n",
    "    \n",
    "    try:\n",
    "        cap_obj = test_results[img_name]\n",
    "        cap_obj.add(caption_number, caption)\n",
    "    except Exception as e:\n",
    "#         print str(e)\n",
    "        feature_dataset = h5py.File('../data/flicker8k/preprocessed/test_features.h5', 'r')\n",
    "        img_features = feature_dataset[img_name]['cnn_features'][:]\n",
    "\n",
    "        # image_filenames = get_image_filenames(dataset_directory + '/' + img_list_file)\n",
    "\n",
    "        # print img_features.shape\n",
    "        features = np.array([img_features])\n",
    "\n",
    "        text_in = np.zeros((1,gen.max_token_len))\n",
    "        text_in[0][:] = np.full((gen.max_token_len,), 0)\n",
    "        text_in[0][0] = 4230\n",
    "\n",
    "        # print features,text_in\n",
    "        arr = []\n",
    "        zeros = np.array([np.zeros(512)])\n",
    "        for arg in range(gen.max_token_len-1):\n",
    "            pred = model.predict([features, text_in])\n",
    "            tok = np.argmax(pred[0][arg])\n",
    "            word = gen.id_to_token[tok]\n",
    "            text_in[0][arg+1] = tok\n",
    "            if word == '<end>':\n",
    "                break\n",
    "            arr.append(word)\n",
    "\n",
    "        arr.append('.')\n",
    "        cap_obj = Caption(img_name)\n",
    "        cap_obj.add(caption_number, caption)\n",
    "        cap_obj.result = ' '.join(arr)\n",
    "        test_results.update({img_name: cap_obj})\n",
    "        \n",
    "        import pickle\n",
    "        pickle.dump(test_results, open('../data/flicker8k/preprocessed/test_results.p', 'wb') )\n",
    "bar.update(len(captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code for importing tested results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Caption:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.captions = ['','','','','']\n",
    "        self.result = ''\n",
    "        \n",
    "    def add(self, caption_number, caption):\n",
    "        self.captions[caption_number] = caption\n",
    "        \n",
    "test_results = pickle.load(open('../data/flicker8k/preprocessed/test_results.p', 'rb'))\n",
    "\n",
    "for img_name in test_results:\n",
    "    ground_truth = test_results[img_name].captions\n",
    "    result = test_results[img_name].result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
