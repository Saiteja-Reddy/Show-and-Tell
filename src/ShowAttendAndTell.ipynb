{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from generator import Generator\n",
    "from models import *\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set Tensorflow backend to avoid full GPU pre-loading\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config = config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Generator\n"
     ]
    }
   ],
   "source": [
    "print \"Loading Generator\"\n",
    "gen = Generator(dataset_directory = '/scratch/jyotish/show_and_tell_coco/data', cnn_model = 'inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model\n"
     ]
    }
   ],
   "source": [
    "print \"Generating model\"\n",
    "model = captioning_model(\n",
    "            gen.img_feature_size,\n",
    "            gen.embedding_size,\n",
    "            gen.max_token_len,\n",
    "            gen.vocab_size)\n",
    "model.compile('adamax', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved model if necessary\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/scratch/jyotish/show_and_tell_coco/data/COCO/models/initial_attend_epoch_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 1/1\n",
      " 732/6470 [==>...........................] - ETA: 50:41 - loss: 1.6951 - acc: 0.7848"
     ]
    }
   ],
   "source": [
    "batch_size = gen.batch_size\n",
    "print \"Start training\"\n",
    "\n",
    "prev_loss = 10\n",
    "for i in range(1):\n",
    "    hist = model.fit_generator(\n",
    "                gen.pullData(),\n",
    "                epochs=1,\n",
    "                steps_per_epoch=int(gen.training_samples_count / (batch_size)), \n",
    "                shuffle = True, verbose = 1#, callbacks = [checkpointer]\n",
    "               )\n",
    "#     if hist.history['loss'][-1] < prev_loss:\n",
    "#         prev_loss = hist.history['loss'][-1]\n",
    "#         print 'Saving ~COCO/models/attention_' + str(i*10) + '.h5'\n",
    "#         model.save('/scratch/jyotish/show_and_tell_coco/data/COCO/models/attention_' + str(i*10) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/scratch/jyotish/show_and_tell_coco/data/COCO/models/initial_attend_epoch_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For runtime testing only ###\n",
    "\n",
    "from IPython.display import Image\n",
    "from process_images import *\n",
    "\n",
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "dataset_directory = '/scratch/jyotish/show_and_tell_coco/data/COCO/extracted'\n",
    "img_list_file = 'val2014'\n",
    "annFile = '{}/annotations/instances_{}.json'.format(dataset_directory, img_list_file)\n",
    "\n",
    "coco=COCO(annFile)\n",
    "imgIds = coco.getImgIds();\n",
    "\n",
    "# img_filenames = ['2943023421_e297f05e11.jpg']\n",
    "# img_directory = '/scratch/jyotish/show_and_tell_coco/data/COCO/extracted/test2014'\n",
    "\n",
    "img_model, target_size, output_shape, preprocess_input = get_cnn_model('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = [imgIds[np.random.randint(0,len(imgIds))]]\n",
    "\n",
    "preprocessed_images = build_image_features(img_id, coco, \n",
    "                         target_size, output_shape,\n",
    "                         preprocess_input,\n",
    "                         img_list_file, dataset_directory,\n",
    "                         [])\n",
    "\n",
    "preprocessed_images = np.asarray(preprocessed_images)\n",
    "img_features = img_model.predict(preprocessed_images)\n",
    "# img_features = np.asarray([img_features])\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "\n",
    "text_in = np.zeros((1,gen.max_token_len))\n",
    "text_in[0][:] = np.full((gen.max_token_len,), 0)\n",
    "text_in[0][0] = gen.token_to_id['<start>']\n",
    "\n",
    "predictions = []\n",
    "zeros = np.array([np.full((gen.img_feature_size[0] * gen.img_feature_size[1]), 1)])\n",
    "for arg in range(gen.max_token_len-1):\n",
    "    pred = model.predict([img_features, text_in, zeros])\n",
    "    tok = np.argmax(pred[0][arg])\n",
    "    word = gen.id_to_token[tok]\n",
    "    text_in[0][arg+1] = tok\n",
    "#     if word == '<end>':\n",
    "#         break\n",
    "    predictions.append(word)\n",
    "\n",
    "print ' '.join(predictions) + '.'\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For generating test results in bulk\n",
    "\n",
    "from IPython.display import Image\n",
    "import time\n",
    "import string\n",
    "import pickle\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import progressbar\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "# Variables to set / change\n",
    "dataset_directory = '/scratch/jyotish/show_and_tell_coco/data/COCO/extracted'\n",
    "token_file_name = 'val2014'\n",
    "\n",
    "# initialize COCO api for caption annotations\n",
    "annFile = '{}/annotations/captions_{}.json'.format(dataset_directory, token_file_name)\n",
    "coco_caps = COCO(annFile)\n",
    "\n",
    "# Load all captions\n",
    "annotation_ids = coco_caps.getAnnIds();\n",
    "annotations = coco_caps.loadAnns(annotation_ids)\n",
    "\n",
    "class Caption:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.captions = []\n",
    "        self.result = ''\n",
    "        \n",
    "    def add(self, caption):\n",
    "        self.captions.append(caption)\n",
    "        \n",
    "test_results = {}\n",
    "\n",
    "for annotation in annotations[:200]:\n",
    "    caption = annotation['caption']\n",
    "    img_name = annotation['image_id']\n",
    "    caption = str(caption).translate(None, string.punctuation).lower()\n",
    "    \n",
    "    try:\n",
    "        cap_obj = test_results[str(img_name)]\n",
    "        cap_obj.add(caption)\n",
    "    except Exception as e:\n",
    "#         print str(e)\n",
    "        feature_dataset = h5py.File('/scratch/jyotish/show_and_tell_coco/data/COCO/preprocessed/test_features.h5', 'r')\n",
    "        img_features = feature_dataset[str(img_name)]['cnn_features'][:]\n",
    "\n",
    "        # image_filenames = get_image_filenames(dataset_directory + '/' + img_list_file)\n",
    "\n",
    "        # print img_features.shape\n",
    "        features = np.array([img_features])\n",
    "\n",
    "        text_in = np.zeros((1,gen.max_token_len))\n",
    "        text_in[0][:] = np.full((gen.max_token_len,), 0)\n",
    "        text_in[0][0] = 4230\n",
    "\n",
    "        # print features,text_in\n",
    "        arr = []\n",
    "        zeros = np.array([np.zeros(512)])\n",
    "        for arg in range(gen.max_token_len-1):\n",
    "            pred = model.predict([features, zeros, text_in])\n",
    "            tok = np.argmax(pred[0][arg])\n",
    "            word = gen.id_to_token[tok]\n",
    "            text_in[0][arg+1] = tok\n",
    "            if word == '<end>':\n",
    "                break\n",
    "            arr.append(word)\n",
    "\n",
    "        arr.append('.')\n",
    "        cap_obj = Caption(img_name)\n",
    "        cap_obj.add(caption)\n",
    "        cap_obj.result = ' '.join(arr)\n",
    "        test_results.update({img_name: cap_obj})\n",
    "#         print cap_obj.result\n",
    "        \n",
    "import pickle\n",
    "pickle.dump(test_results, open('/scratch/jyotish/show_and_tell_coco/data/COCO/preprocessed/test_results.p', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for importing tested results\n",
    "import pickle\n",
    "\n",
    "class Caption:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.captions = ['','','','','']\n",
    "        self.result = ''\n",
    "        \n",
    "    def add(self, caption_number, caption):\n",
    "        self.captions[caption_number] = caption\n",
    "        \n",
    "test_results = pickle.load(open('../data/flicker8k/preprocessed/test_results.p', 'rb'))\n",
    "\n",
    "for img_name in test_results:\n",
    "    ground_truth = test_results[img_name].captions\n",
    "    result = test_results[img_name].result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
